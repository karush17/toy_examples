{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "QMowjo0yy6Vq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "l-_2yFv5tDua"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import unittest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toy Model Function"
      ],
      "metadata": {
        "id": "ra-lJWXczm0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "  def __init__(self, vocab_size):\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "  def forward(self, sequence):\n",
        "    return np.random.uniform(size = (self.vocab_size,))"
      ],
      "metadata": {
        "id": "d5PyrLprzo__"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoding Class"
      ],
      "metadata": {
        "id": "PV1zBJyYy_yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BeamSearch:\n",
        "\n",
        "  def __init__(self, model, vocab_size = 1000, beam_size = 5):\n",
        "    self.vocab_size = vocab_size\n",
        "    self.beam_size = beam_size\n",
        "    self.tokens = [i for i in range(vocab_size)]\n",
        "    self.model = model\n",
        "\n",
        "  def get_top_k(self, sequence):\n",
        "    probs = self.model.forward(sequence)\n",
        "    topk_probs, topk_tokens = torch.Tensor(probs).topk(self.beam_size)\n",
        "    return topk_tokens.tolist(), topk_probs.tolist()\n",
        "\n",
        "  def sample(self, prompt, seq_len):\n",
        "    self.beams = [(prompt, 0)] * self.beam_size\n",
        "    self.count = 0\n",
        "    while self.count != seq_len:\n",
        "      self.all_candidates = []\n",
        "      for sequence, logprob in self.beams:\n",
        "        tokens, prob = self.get_top_k(sequence)\n",
        "        for i in range(self.beam_size):\n",
        "          self.all_candidates.append(\n",
        "              (sequence + [tokens[i]],\n",
        "              logprob + prob[i])\n",
        "          )\n",
        "      self.beams = sorted(self.all_candidates, key = lambda x: x[1], reverse = True)[:self.beam_size]\n",
        "      self.count += 1\n",
        "    return sorted(self.beams, key = lambda x: x[1], reverse = True)[0][0]\n",
        "\n"
      ],
      "metadata": {
        "id": "lRHpTnsVzBIv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests"
      ],
      "metadata": {
        "id": "sOIzUUnQ7ehv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestClass(unittest.TestCase):\n",
        "\n",
        "  def setUp(self):\n",
        "    self.beam_size = 5\n",
        "    self.vocab_size = 1000\n",
        "    self.model = Model(self.vocab_size)\n",
        "    self.decoder = BeamSearch(self.model, vocab_size = self.vocab_size, beam_size = self.beam_size)\n",
        "    self.prompt = [1]\n",
        "    self.seq_len = 20\n",
        "\n",
        "  def test_decoder_output(self):\n",
        "    output = self.decoder.sample(self.prompt, self.seq_len)\n",
        "    self.assertEqual(len(output), self.seq_len + 1)\n",
        "\n",
        "  def test_beam_sizes(self):\n",
        "    output = self.decoder.sample(self.prompt, self.seq_len)\n",
        "    self.assertEqual(len(self.decoder.beams), self.beam_size)\n",
        "\n",
        "  def test_candidate_sizes(self):\n",
        "    output = self.decoder.sample(self.prompt, self.seq_len)\n",
        "    self.assertEqual(len(self.decoder.all_candidates), self.beam_size**2)\n",
        "\n",
        "  def test_counter(self):\n",
        "    output = self.decoder.sample(self.prompt, self.seq_len)\n",
        "    self.assertEqual(self.decoder.count, self.seq_len)\n",
        "\n",
        "  def test_token_range(self):\n",
        "    output = self.decoder.sample(self.prompt, self.seq_len)\n",
        "    self.assertGreater(self.vocab_size, max(output))\n",
        "    self.assertLess(0, min(output))\n",
        "\n"
      ],
      "metadata": {
        "id": "MtnElxkV9P-U"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute Decoder"
      ],
      "metadata": {
        "id": "Po_JU-Sm_8R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  unittest.main(argv = [\"\"], verbosity = 2, exit = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "906GovCc7gWP",
        "outputId": "8c115bec-32ea-4418-9f2f-8a3c84bad2a5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_beam_sizes (__main__.TestClass.test_beam_sizes) ... ok\n",
            "test_candidate_sizes (__main__.TestClass.test_candidate_sizes) ... ok\n",
            "test_counter (__main__.TestClass.test_counter) ... ok\n",
            "test_decoder_output (__main__.TestClass.test_decoder_output) ... ok\n",
            "test_token_range (__main__.TestClass.test_token_range) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.056s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KuNlhvCxADFz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}